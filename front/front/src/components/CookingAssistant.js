// components/CookingAssistant.js
import React, { useEffect, useRef, useState, useCallback } from "react";
import { AIResponse, fetchTTS } from "../api";
import { useCharacter } from "../contexts/CharacterContext";
import CircularTimer from "./CircularTimer";

function CookingAssistant({ recipe, currentStep, setCurrentStep }) {
  const { character } = useCharacter();
  const audioRef = useRef(null);
  const recognitionRef = useRef(null);
  const abortControllerRef = useRef(null);
  const [isAssistantOn, setIsAssistantOn] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [timer, setTimer] = useState(null);
  const [timeLeft, setTimeLeft] = useState(0);
  const [timerActive, setTimerActive] = useState(false);
  const alarmAudioRef = useRef(null);
  const [alarmPlaying, setAlarmPlaying] = useState(false);
  const [format] = useState("mp3");

  const playCloudTTS = useCallback(async (text) => {
    try {
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
        audioRef.current = null;
      }
      if (abortControllerRef.current) abortControllerRef.current.abort();

      const abortController = new AbortController();
      abortControllerRef.current = abortController;
      const response = await fetchTTS(
          text,
          abortControllerRef.current,
          character,
          "wav"
        );
      const data = await response.json();
      
      if (data.audioBase64) {
        const mime = "wav" === "wav" ? "audio/wav" : "audio/mp3";
        const blob = new Blob(
          [Uint8Array.from(atob(data.audioBase64), c => c.charCodeAt(0))],
          { type: mime }
        );
        const url = URL.createObjectURL(blob);
        const audio = new Audio(url);
        audioRef.current = audio;
        await audio.play();
      }
    } catch (err) {
      if (err.name !== "AbortError") console.error("TTS ì˜¤ë¥˜:", err);
    }
  },
 [character, format]
);

  const handleAssistantAction = (data) => {
    if (!data || !data.action) return;

    switch (data.action) {
      case "next_step":
        setCurrentStep((prev) => Math.min(prev + 1, recipe.instructions.length - 1));
        break;
      case "prev_step":
        setCurrentStep((prev) => Math.max(prev - 1, 0));
        break;
      case "repeat_step":
        playCloudTTS(recipe.instructions[currentStep]);
        break;
      case "set_timer":
        if (data.time) {
          let seconds = parseInt(data.time, 10);
          if (data.unit === "ë¶„") seconds *= 60;
          setCookingTimer(seconds);
        }
        break;
      case "cancel_timer":
        setTimer(null);
        setTimeLeft(0);
        setTimerActive(false);
        timerActive(false);
        stopAlarm();
        break;
      case "response":
        if (data.answer) playCloudTTS(data.answer);
        break;
      default:
        console.warn("ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹:", data.action);
    }
  };

  const fetchAIResponse = async (question) => {
    if (!character) {
           alert("ë¨¼ì € ìƒë‹¨ì—ì„œ ìºë¦­í„°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.");
           return;
         }
    try {
      const response = await AIResponse(question, recipe, character);
      const data = await response.json();
      handleAssistantAction(data);
    } catch (error) {
      console.error("AI ì‘ë‹µ ì˜¤ë¥˜:", error);
    }
  };

  const startListening = () => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      console.error("ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.");
      return;
    }
  
    // recognition ê°ì²´ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if (!recognitionRef.current) {
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.lang = "ko-KR";
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = false;
  
      // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
      recognitionRef.current.onstart = () => {
        console.log("ğŸ™ï¸ ìŒì„± ì¸ì‹ ì‹œì‘ë¨...");
        setIsListening(true);
        setIsAssistantOn(true);
      };
  
      recognitionRef.current.onresult = (event) => {
        const voiceText = event.results[event.results.length - 1][0].transcript.trim();
        console.log("ìŒì„± ì…ë ¥:", voiceText);
        fetchAIResponse(voiceText);
      };
  
      recognitionRef.current.onerror = (event) => {
        console.error("ìŒì„± ì¸ì‹ ì˜¤ë¥˜:", event.error);
        setIsListening(false);
      };
  
      recognitionRef.current.onend = () => {
        console.log("ìŒì„± ì¸ì‹ ì¢…ë£Œë¨");
        setIsListening(false);
  
        // assistantê°€ ì¼œì ¸ ìˆë‹¤ë©´ ìë™ ì¬ì‹œì‘
        if (isAssistantOn) {
          setTimeout(() => {
            if (!isListening) {
              try {
                recognitionRef.current?.start();
                setIsListening(true);
              } catch (error) {
                console.warn("ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì‹¤íŒ¨:", error);
              }
            }
          }, 1000);
        }
      };
    }
  
    // ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: isListeningì´ falseì¼ ë•Œë§Œ start í˜¸ì¶œ
    if (!isListening) {
      try {
        recognitionRef.current.start();
      } catch (error) {
        if (error.name === "InvalidStateError") {
          console.warn("ì´ë¯¸ ìŒì„± ì¸ì‹ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.");
        } else {
          console.error("startListening ì˜¤ë¥˜:", error);
        }
      }
    }
  };
  

  const stopListening = () => {
    recognitionRef.current?.stop();
    setIsAssistantOn(false);
  };

  // AI ì–´ì‹œìŠ¤í„´íŠ¸ ë²„íŠ¼ í´ë¦­ ì‹œ ON/OFF
  const toggleAssistant = () => {
    if (isAssistantOn) {
      stopListening();
      setIsListening(false);
    } else {
      startListening();
      setIsAssistantOn(true);
    }
  };

  const setCookingTimer = (seconds) => {
    setTimeLeft(seconds);
    setTimer(seconds);
    setTimerActive(true);
    playCloudTTS(`${seconds}ì´ˆ íƒ€ì´ë¨¸ë¥¼ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.`);
  };

  const stopAlarm = () => {
    if (alarmAudioRef.current) {
      alarmAudioRef.current.pause();
      alarmAudioRef.current.currentTime = 0;
      setAlarmPlaying(false);
    }
    setTimer(null);
    setTimeLeft(0);
    setTimerActive(false);
  };

  useEffect(() => {
    return () => {
      if (abortControllerRef.current) {
        abortControllerRef.current.abort();
      }
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current = null;
      }
    };
  }, []);

  useEffect(() => {
    if (!recipe || !recipe.instructions) return;

    const currentText = recipe.instructions[currentStep];
    if (currentText) {
      playCloudTTS(currentText);
    }
  }, [currentStep, recipe, playCloudTTS]);


  return (
    <div style={{ marginTop: "30px" }}>
      <button
        onClick={toggleAssistant}
        style={{ marginTop: "20px", padding: "10px 15px", fontSize: "1rem", backgroundColor: isAssistantOn ? "red" : "#4CAF50", color: "#fff", border: "none", borderRadius: "5px", cursor: "pointer" }}
      >
        {isAssistantOn ? "AI ì–´ì‹œìŠ¤í„´íŠ¸ ë„ê¸°" : "AI ì–´ì‹œìŠ¤í„´íŠ¸ ì¼œê¸°"}
      </button>
      {timerActive && (
        <CircularTimer
          timeLeft={timeLeft}
          isRunning={isAssistantOn}
          initialTime={timer}
          onStop={() => {setTimerActive(false); stopAlarm();}}
        />
      )}
    </div>
  );
}

export default CookingAssistant;
